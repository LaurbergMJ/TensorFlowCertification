{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 2 Lab - getting to learn the Fashion-MNIST dataset\n",
    "\n",
    "<p>This notebook contains my own re-make of the topics covered in ungraded lab of \n",
    "week 2 in course 2.\n",
    "The main topic of this lab is to get to learn and work with the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset made by Zalando\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion-MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling load_data() on the fmnist object, returns two tuples containing two lists each.\n",
    "#These tuples will be the training and testing values for the graphics that contain the clothing\n",
    "#items and their labels\n",
    "\n",
    "#Load the training and test split of the fashion mnist dataset \n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's try to take a look at a training example from the data, to give us an idea of what these look like. Let's look at both an image and a label data entry\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 7\n",
      "\n",
      "IMAGE PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   1   1   0   1   0   0   0   0  22   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   2   0   0   3   0   0   0  17   0   0  12 138   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   0   0   0  23 251 225 196 222 186 255 159   0 255  99   0   4   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0 126 218 233 212 210 215 202 242  11 142 255  76   0  12   1]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0  31 233 240 225 197 202 202 210 201 173 125 227 237  39   0   9   0]\n",
      " [  0   0   1   1   5   6   0   0   0  38 156 255 223 205 209 212 186 210 203 207 199 199 155 162 176 133  93   0]\n",
      " [  0   0   0   0   0   0   0  22 202 226 238 211 194 194 207 206 215 198 212 211 206 200 195 179 192 207 141   0]\n",
      " [  0   0  22  61  82 108 150 192 176 180 195 194 195 198 180 180 179 175 207 209 215 224 219 207 189 181 153   0]\n",
      " [  0 157 169 158 152 154 158 156 174 184 202 192 191 164 166 191 189 179 170 180 185 202 217 215 204 205 195   0]\n",
      " [143 238 183 185 183 172 154 147 135 136 147 159 176 138  79 142 192 202 216 206 188 208 195 171 173 129 164   5]\n",
      " [ 11 199 213 196 168 181 230 210 216 199 179 176 171 163 192 163 193 232 188 171 229 224 129 114 171  90 154  66]\n",
      " [  0  16 176 214 209 192 174 148 112 153 163 158 156 193 195 168 159 129 137 127 133 122 131 138 132 134 165 130]\n",
      " [  0   0   0   0 106 188 217 255 202 202 155 135 142 201 200 197 170 144 212 198 196 218 216 219 212 204 193  68]\n",
      " [  0   0   0   0   0   0   0  26  97 146 172 204 196 174 159 138 113  82  72  50  38  31  10   3   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# we can choose an index value between 0 an 59999, since there is a total of 60,000 images in the dataset\n",
    "index = 175 \n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image \n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that all of the values are between 0 and 255. If you are training a neural network in image processing, for various reasons it will usually learn better, \n",
    "if we scale all values down to values between 0 and 1. \n",
    "This process is called _normalization_ \n",
    "\n",
    "In Python it is easy to do normalization on arrays, without having to use looping structures\n",
    "\n",
    "Let's do that next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the pixel values of the train and test images \n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now design the model                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the classification model\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
    "                            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little explanation of the elements in the model structure above: \n",
    "\n",
    "**Sequential**:\n",
    "\n",
    " - Defines a sequence of layers in the neural network\n",
    "\n",
    " **Flatten**:\n",
    "\n",
    " - Flatten takes the the square image of n x n pixels matrix, and turns that square into a 1-dimensional array\n",
    "\n",
    " **Dense**:\n",
    "\n",
    " - Adds a layer of neurons\n",
    "\n",
    " Each layer of neurons need an activation function to tell them what to do. There are lots of options but here we just use these:\n",
    "\n",
    "  - ReLU:\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "It basically just passes values 0 or greater to the next layer in the network\n",
    "\n",
    "**Softmax**:\n",
    "\n",
    " - Takes a list of values and scales these so the sum of all elements will be equal to 1. When applied to model outputs you can think of the scaled values as the probability for that class. \n",
    " For example, in our classification model which has 10 units in the output dense layer, having the highest value at index=4, means that the model is most confident that the input clothing image belongs to that category (ie. coat)\n",
    "\n",
    " If the value is at index=5 the category is sandal and so forth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of the softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      "class with highest probability: 2\n"
     ]
    }
   ],
   "source": [
    "#Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "#Feed the inputs to a softmax activation function \n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of the softmax function: {outputs.numpy()}')\n",
    "\n",
    "#Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "#Get the index with highest value \n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to do now that the model is defined, is to actually build it. We do this by compiling it with an optimizer and loss function as before -- and then we train it by calling _model.fit()_ asking it to fit our training data to our training labels\n",
    "\n",
    "The model will then figure out the relationship between the training data and its actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5000 - accuracy: 0.8256\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3745 - accuracy: 0.8648\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3377 - accuracy: 0.8773\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3131 - accuracy: 0.8852\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2953 - accuracy: 0.8911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25568726ec0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's actually compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is done training, we can see from the above that this model specification found a pattern match between the image and the labels that worked 89.11% of the time (accuracy score)\n",
    "\n",
    "Next we try to test how the model will do with unseen data, by evaluating the model on test images and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3419 - accuracy: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3418787717819214, 0.8773999810218811]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on unseen data \n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the evaluation shows, the model has an accuray of approx. 88% on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 \n",
    "\n",
    "We are asked to run the below code and answer a few questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 855us/step\n",
      "[4.5424604e-05 1.4828730e-08 2.6083151e-06 2.2031463e-07 1.5912965e-05 4.6398580e-02 1.5606549e-05 4.5061149e-02 2.8664910e-04 9.0817380e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1Q1: What does this list represent?\n",
    "\n",
    " 1. It's 10 random meaningless values \n",
    " 2. It's the first 10 classifications that the computer mande\n",
    " 3. It's the probability that this item is each of the 10 classes\n",
    "\n",
    " ANSWER: \n",
    " The correct answer is number #\n",
    "\n",
    "### E1Q2: How do you know that this list tells you that the item is an ankle boot?\n",
    "\n",
    " 1. There's not enough information to answer that question \n",
    " 2. The 10th element on the list is the biggest, and the ankle boot is labelled 9\n",
    " 3. The ankle boot is label 9, and there are 0->9 elements in the list\n",
    "\n",
    " ANSWER: \n",
    " The correct answer is number #! Since the 10th element in the list is the highest value -> the highest probability of belonging to that category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 \n",
    "\n",
    "Here we are focusing on the layers of the model. Experiment with different values for the dense layer with 512 neurons. What different results do you get for loss, training time etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4697\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3584\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3209\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2952\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2781\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3272\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[1.09742558e-07 2.20290460e-07 1.63339020e-09 6.06345585e-10\n",
      " 2.88714705e-08 2.36959197e-03 1.26459483e-07 1.89479198e-02\n",
      " 1.00186375e-08 9.78681982e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "                loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E2Q1: increase to 1024 Neurons - what's the impact?\n",
    "\n",
    " 1. Training takes longer, but is more accurate \n",
    " 2. Training takes longer, but no impact on accuracy\n",
    " 3. Training takes the same time, but is more accurate\n",
    "\n",
    "ANSWER: # - Adding more Neurons we have to do more calculations, slowing down the process. In this case they have a good impact - we do get more accurate. That doesn't mean it's always a case of \"more is better\", you can hit the \"law of diminishing returns\" very quickly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 \n",
    "\n",
    "E3Q1: What would happen of you remove the Flatten() layer. Why do you think that's the case? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Projekter\\TensorFlow_certification\\Coursework\\DeepLearning - TensorFlow Developer\\Course1\\Week2\\week2_lab.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu),\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m10\u001b[39m, activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msoftmax)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(training_images, training_labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m classifications \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_images)\n",
      "File \u001b[1;32mc:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_k8gxoqz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "                loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: We get an error about the shape of the data. It reinforces the rule of thumb, that the first layer in our network should be the same shape as our data. Right now our data is 28x28 images, and 28 layers of 28 neurons would be infeasible, so it makes more sense to 'flatten' that 28x28 into a 784x1. Instead of writing all the code to handle that ourselves, we add the Flatten() layer at the beginning, and when the arrays are loaded into the model later, they'll automatically be flattened for us.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4 \n",
    "\n",
    "Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10? For example, try training network with 5!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_23820\\1865654830.py\", line 8, in <cell line: 8>\n      model.fit(training_images, training_labels, epochs=5)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 9 which is outside the valid range of [0, 5).  Label values: 5 9 9 4 3 1 6 3 4 4 0 1 1 2 4 2 4 0 2 4 1 9 8 8 6 4 3 1 0 5 6 2\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_158807]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Projekter\\TensorFlow_certification\\Coursework\\DeepLearning - TensorFlow Developer\\Course1\\Week2\\week2_lab.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1024\u001b[39m, activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu),\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m5\u001b[39m, activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msoftmax)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(training_images, training_labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Projekter/TensorFlow_certification/Coursework/DeepLearning%20-%20TensorFlow%20Developer/Course1/Week2/week2_lab.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m classifications \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_images)\n",
      "File \u001b[1;32mc:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_23820\\1865654830.py\", line 8, in <cell line: 8>\n      model.fit(training_images, training_labels, epochs=5)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Projekter\\py_venv\\.venv\\lib\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 9 which is outside the valid range of [0, 5).  Label values: 5 9 9 4 3 1 6 3 4 4 0 1 1 2 4 2 4 0 2 4 1 9 8 8 6 4 3 1 0 5 6 2\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_158807]"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "                loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: We get an error as soon as the model finds an unexpected value. Another rule of thumb - the number of neurons in the last layer should match the number of classes you are classifying for. In this case it's the digits 0-9 so there are 10 of them, hence we should have 10 neurons in our final layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5 \n",
    "\n",
    "Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4668\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3590\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3210\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.2966\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2793\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3457\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "[5.2610169e-08 4.5362207e-09 4.6501690e-08 2.0587354e-08 1.2000093e-08\n",
      " 1.4191066e-04 3.3703711e-07 6.9291624e-03 1.3480063e-07 9.9292833e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "                loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: There isn't a significant impact - because this data is very simple! but for more complex cases, extra layers are often necessary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6\n",
    "\n",
    "### E6Q1: Consider the impact of training for more or less epochs. why do you think that would be the case? \n",
    "\n",
    " - Try for 15 epochs -- you'll probably get a model with a much better loss than the one with 5\n",
    " - Try 30 epochs -- you might see the loss value decrease more slowly, and sometimes increases. You'll also likely see that the results of model.evalute() didn't improve much. It can even be slightly worse\n",
    "\n",
    " This is a side effect of something called \"overfitting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4655\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3554\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3170\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2949\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2744\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2599\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 0.2470\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2399\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2282\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2188\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.2101\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2029\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1936\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1853\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1823\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1724\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1688\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1645\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1592\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1529\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1533\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1460\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1413\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1393\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1343\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1337\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1253\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1255\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1244\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1177\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5411862730979919"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "                loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "#classifications = model.predict(test_images)\n",
    "\n",
    "#print(classifications[0])\n",
    "#print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7\n",
    "\n",
    "What is the impact of not normalizing the data (divided by 255) to get values between 0-1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4744\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3574\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3226\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2971\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2802\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3606\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[5.7215317e-07 7.5133482e-09 9.1857842e-08 1.8318741e-07 1.3786276e-07\n",
      " 2.2646420e-02 3.5476504e-07 1.0511803e-01 1.8075802e-07 8.7223405e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "training_images = training_images\n",
    "test_images = test_images\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "                loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: My guess is that it will get more difficult for the model to get good fits and extract more deeply and complex features! When the data is normalized, it should be easier for the model to extract out \"differences\" from one datapoint to another... So, by not normalizing the data I guess it will be more difficult for the data to learn and \"spot\" complex differences (hence features) amongst the datapoints! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8 \n",
    "\n",
    "Introduction to callbacks... Callbacks give us an opportunity to stop the training when a certain level of loss is reached, so that we don't have to wait for the full model to finish, but can finish after a desired level of loss is reached "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3028 - accuracy: 0.0996\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3021 - accuracy: 0.1065\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2993 - accuracy: 0.1236\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2923 - accuracy: 0.1749\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2803 - accuracy: 0.1864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc47c21630>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') >= 0.5): #Experiment with changing this value! \n",
    "            print(\"\\nReached 60% acc. so cancelling training!\")\n",
    "            self.model.stop_training = True \n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2590b067655b4efbefdfc89bcbe63220f2bed4c70a5b65fec08921869d5cbc69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
