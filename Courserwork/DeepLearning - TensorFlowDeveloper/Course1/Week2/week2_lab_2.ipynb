{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ungraded Lab 2 - Using callbacks to Control Training\n",
    "\n",
    "In this lab we will be using the Callbacks API to stop training when a specified metric is met. This is a useful feature so we don't need to complete all epochs but can stop it when a specific threshold is met. \n",
    "\n",
    "For example if we set 1000 epochs and our desired accuracy is already reached at epoch 200, then the training will automatically stop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Normalize the Fashion MNIST dataset\n",
    "\n",
    "Like the previous lab, we will use the Fashion MNIST dataset again for this exercise. And also we will normalize the pixel values to help optimize the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "# Instantiate the dataset API\n",
    "fmnist = tf.keras.datasets.fashion_mnist \n",
    "\n",
    "# Load the dataset \n",
    "(x_train, y_train), (x_test, y_test) = fmnist.load_data()\n",
    "\n",
    "# Normalize the pixel values \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Callback class \n",
    "\n",
    "We can create a callback by defining a class that inherits from the tf.keras.callbacks.Callback base class. \n",
    "\n",
    "We can define available methods, for instance we can use the _on_epoch_end()_ method to check the loss at each training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''\n",
    "        This method stops the training after reaching 60 percent accuracy\n",
    "\n",
    "        Args:\n",
    "          epochs (integer) - index of epoch \n",
    "          logs (dict) - metric results from the training epoch\n",
    "        '''\n",
    "\n",
    "        # check accuracy\n",
    "        if (logs.get('loss') < 0.25):\n",
    "\n",
    "            print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "            self.model.stop_training = True \n",
    "\n",
    "# Instantiate class \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and compile the model\n",
    "\n",
    "Next, we will define and compile the model. The architecture will be similar to the one we built in previous labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#Compile the model \n",
    "model.compile(optimizer=tf.optimizers.Adam(), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model \n",
    "\n",
    "To set the callback we simply set the _callbacks_ parameter to the myCallback instance we declared before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4745 - accuracy: 0.8315\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3579 - accuracy: 0.8681\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3217 - accuracy: 0.8815\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2991 - accuracy: 0.8880\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2811 - accuracy: 0.8958\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2651 - accuracy: 0.9015\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2534 - accuracy: 0.9054\n",
      "Epoch 8/10\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9095\n",
      "Loss is lower than 0.4 so cancelling training!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2431 - accuracy: 0.9095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ecf0bbfee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model with a callback \n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2590b067655b4efbefdfc89bcbe63220f2bed4c70a5b65fec08921869d5cbc69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
