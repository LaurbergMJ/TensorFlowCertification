{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of Course 1\n",
    "\n",
    "In this notebook I make a review of all the things and techniques that we learned in course 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture - The Sequential model\n",
    "\n",
    "In this first course we build a range of neural networks by utilizing the fundamental methods of the TensorFlow/Keras **Sequential** Model! \n",
    "\n",
    "### Sequential model - layers\n",
    "\n",
    "The Sequential model architecture let's us build up a network structure by adding layers on top of each other one by another. We have learned how the Sequential model structure often builds from scratch by starting out by adding a selected number layers. \n",
    "\n",
    "The first types of layers we defines are the Dense- and the Flatten layers: \n",
    "\n",
    "##### **Dense layer:**\n",
    "\n",
    "The Dense layer adds a layer of Neurons. Each Dense layer needs an activation functions to tell the neurons what to do. There are a lot of options for choosing activation functions to choose from, here we are mainly using: \n",
    "\n",
    "_Relu:_\n",
    "    If x > 0 then x, else 0\n",
    "    \n",
    "_Sigmoid_:\n",
    "    An S-shaped curved logistic funtion (exp(x) / exp(x) +1) that returns 0 or 1\n",
    "    \n",
    "_Softmax_:\n",
    "    Takes a list of values and scales these so the sum of all elements will equal 1. When applied to model outputs we can think of the scaled values as the probability for that class. This is used for multi-class classfication, when oiutput needs to be classified as 1 out of multiple classes! \n",
    "\n",
    "##### **Flatten layer:**\n",
    "\n",
    "The _Flatten_ layer usually comes as the first layer in the model, as this layer serves the purpose of turning the square matrix image of nxn pixels into a 1-dimensional array which can then be feeded into the model! \n",
    "\n",
    "Let's look at a simple example of a simple Model architecture: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Compilation - compile and train the model\n",
    "\n",
    "The next thing to do after having built the model architecture, is to actually build it! \n",
    "\n",
    "We build the models by compiling it!\n",
    "\n",
    "When compiling the model we need to make some choices on what specifications we are going to use for:\n",
    "\n",
    "_optimizer:_\n",
    "Here we must specifiy which optimizer to use when building the model. We have broad range of different optimizers available in TF, which is another area to dig into in order to pick which optimizer works best for the model at hand. In this example we are using the **Adam()** optimizer!\n",
    "\n",
    "_loss:_\n",
    "We must also specify which type of loss function the model should use. This is again a scientific question that depends on the type of data and model we working with. In this example we use the _sparse_categorical_crossentropy_ loss function\n",
    "\n",
    "_metrics:_\n",
    "This setting let's us choose which metric we want to use as our measurement for the performance of the model. Here we again have different choices available, and in this example we use the **accuracy** measurement metric!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compile the model:\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                metrics = ['accuray'])\n",
    "\n",
    "# And then we can actually take the model and build it:\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Evaluation\n",
    "\n",
    "After training the model we can evaluate the model by using evaluation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice: \n",
    "\n",
    "* What is the effect of adding more neurons in a Dense layer?\n",
    "    - More calculations = slower!\n",
    "    - We expect also to get a better accuracy, but gives a deeper (more expensive) network\n",
    "    - Be aware of the \"Law of Diminishing returns! Deeper network not always gives a better accuracy!\n",
    "\n",
    "* What is the effect of adding more layers to the network?\n",
    "    - Adding more layers gives a deeper network, this should mean that for more complex data more complex networks are needed, and thus deeper networks should give better accuracy! But again, beware of the \"Law of diminishing returns\"!\n",
    "\n",
    "* Effect of adding more epochs!\n",
    "    - Beware of \"overfitting\" \n",
    "    - In principle more epochs should increase accuracy, but often comes at the price of more     overfitting\n",
    "\n",
    "* Effect of not Normalizing the data\n",
    "    - Not normalizing will often make it more difficult for the model to find patterns\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Using Callbacks\n",
    "\n",
    "We have seen how we can use callbacks as a way to control the training sequence of the models. By using a callback function we have seen how we can use a callback to stop the model from training further, once a certain amount of a specified metric is reached! \n",
    "\n",
    "An example of creating a callback class was as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''\n",
    "        This method stops the training after reaching 60 percent accuracy\n",
    "\n",
    "        Args:\n",
    "          epochs (integer) - index of epoch \n",
    "          logs (dict) - metric results from the training epoch\n",
    "        '''\n",
    "\n",
    "        # check accuracy\n",
    "        if (logs.get('loss') < 0.25):\n",
    "\n",
    "            print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "            self.model.stop_training = True \n",
    "\n",
    "# Instantiate class \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the callback function when training the model, we add the callback funtion in the fit() method of the model object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a callback to the model object\n",
    "model.fit(x_train, y_train, epochs=111, callbacks=[callbacks]) \n",
    "# Notice how the callback is added to the model object!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Improvement using Convolutions\n",
    "\n",
    "#### Convolutional Layers:\n",
    "\n",
    "We use the built-in Conv2D layer type when adding convolutional layers! The parameters we add to this layers can be summarized as:\n",
    "\n",
    " 1. Number of convolutions: Good to use powers of 2!\n",
    " 2. Size: often 3x3, 5x5, 7x7 etc.\n",
    " 3. Activation function: Sigmoid, Relu etc. \n",
    " 4. First layer we add the input_shape\n",
    "\n",
    "Normally we'll always follow a convolutional layer with a MaxPooling layer...\n",
    "\n",
    "##### MaxPooling2D\n",
    "\n",
    "A layer that is designed to compress the image, while maintaining the content of the features that were highlighted by convolution! \n",
    "\n",
    "By specifying (2,2) for the MaxPooling the effect is to quarter the size of the image! \n",
    "\n",
    "Some noticeable effects of convolutions: \n",
    "\n",
    " 1. Higher number of convolutions - training time up but accuracy should go up too! \n",
    " 2. Removing final convolution - training time up, while accuracy drops! \n",
    " 3. Adding more convolutions - training time up, accuracy should go up too! \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Training with ImageDataGenerator\n",
    "\n",
    "#### Data Preprocessing:\n",
    "\n",
    "Data generators will read pictures and then convert them to _float32_ tensors and feed them to the model! Generators will yield batches of images and their labels\n",
    "\n",
    "**Normalization**\n",
    "\n",
    "We will always want to normalize the data that feeds into a network! \n",
    "\n",
    "In ImageDataGenerator we do this by setting the input parameter: _rescale_ when initializing the ImageDataGenerator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "#Here we normalize the pixels to values between 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flow from directory**\n",
    "\n",
    "the ImageDataGenerator allows us to instantiate generators of augmented image batches via .flow(data,labels) or .flow_from_directory(directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"directory\",\n",
    "    target_size=(300,300), # Here we can set the desired number of pixels we want \n",
    "    batch_size=128,    # Here we can set the desired batch size\n",
    "    class_mode='binary' # This setting depends on the type of data we are trying to model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**\n",
    "\n",
    "We can now setup the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch, \n",
    "    epochs=15, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageDateGenerator with Validation:\n",
    "\n",
    "Here we can now set up data generators for both training and validation sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './horse-or-human/',\n",
    "    target_size=(300,300),\n",
    "    batch_size=128,\n",
    "    # Since we use binary_crossentropy loss, we will need binary labels\n",
    "    class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 128 using validation_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    './validation-horse-or-human/',\n",
    "    target_size = (300, 300),\n",
    "    batch_size=32,\n",
    "    # Since we use binary_crossentropy loss, we need binary labels\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then setup the model for traning with both training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = 8, \n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of Compacted Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)), # Here setting the smaller number of pixels per picture!\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    # This is the second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    # This is the third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    # ... We can put more conv. layers if we want to see the effect! \n",
    "\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess the data when compacting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './horse-or-human/',\n",
    "    target_size=(150,150), \n",
    "    batch_size=128,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    './validation-horse-or-human/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32, \n",
    "    class_mode='binary'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2590b067655b4efbefdfc89bcbe63220f2bed4c70a5b65fec08921869d5cbc69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
