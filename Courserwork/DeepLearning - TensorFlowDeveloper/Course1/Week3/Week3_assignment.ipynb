{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3: Improve MNIST with Convolutions\n",
    "\n",
    "for this exercise we see if we can improve MNIST to 99.5% accuracy or more by adding only a single convolutional layer and a single MaxPooling 2D layer.\n",
    "\n",
    "We should stop training once the accuracy goes above this amount. It should happen in less than 10 epochs, so it's ok to hard code the number of epochs for training, but our training must end once it hits the above metric. If it doesn't, then we'll need to redesign our callback\n",
    "\n",
    "When 99.5% accuracy has been hit, we should print out the string \"Reached 99.5% accuracy so cancelling training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by loading the data. A couple of things to notice: \n",
    " * The data is found in the file **mnist.npz**\n",
    " * **load_data** returns the train and test sets in the form of the tuples (x_train, y_train), (x_test, y_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "current_dir = os.getcwd()\n",
    "data_path = os.path.join(current_dir, \"mnist.npz\")\n",
    "\n",
    "# Get only the training set\n",
    "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important first step when dealing with image data is to preprocess the data. \n",
    "\n",
    "Here we will apply two transformations to the data: \n",
    "\n",
    "* Reshape the data so that it has an extra dimension. The reason for this is that commonly we    will use 3D arrays (without counting the batch dimension) to represent the data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless\n",
    "\n",
    "* Normalize the pixel values so that these are values between 0 and 1. We can achieve this by dividing every value in the array by the maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reshape_and_normalize\n",
    "\n",
    "def reshape_and_normalize(images):\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Reshape the images to add an extra dimension\n",
    "    \n",
    "    # Normalize pixel values \n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
      "\n",
      "Shape of one image after reshaping: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the images in case we run this cell multiple times\n",
    "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "\n",
    "# Apply your function \n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f'Maximum pixel value after normalization: {np.max(training_images)}\\n')\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must complete the callback that will ensure that training will stop after an accuracy of 99.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CLASS: myCallback \n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from correct class\n",
    "\n",
    "    # Define the method that checks the accuracy at the end of each epoch \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally complete the convolutional_model function below. This function should return your convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_model\n",
    "def convolutional_model():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define the model, it should have 5 layers:\n",
    "    # A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function and an input shape that matches that of every image in the training set\n",
    "    # A MaxPooling2D layer with a pool_size of 2x2\n",
    "    # A Flatten layer with no arguments\n",
    "    # A Dense layer with 128 units and ReLU activation function \n",
    "    # A Dense layer with 10 units and softmax activation function \n",
    "    \n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Compile the model \n",
    "    model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1482 - accuracy: 0.9561\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0511 - accuracy: 0.9843\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0311 - accuracy: 0.9902\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0210 - accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0150 - accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9967\n",
      "Reached 99.5% accuracy so canceling training!\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0098 - accuracy: 0.9967\n"
     ]
    }
   ],
   "source": [
    "# Let's save our untrained model\n",
    "model = convolutional_model()\n",
    "\n",
    "# Instantitate the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we get the message that we wanted about our training being stopped after reaching an accuracy of 99.5%, we can conclude that our callback worked as expected! \n",
    "\n",
    "We can then double check by running the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model was trained for 6 epochs\n"
     ]
    }
   ],
   "source": [
    "print(f'Our model was trained for {len(history.epoch)} epochs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2590b067655b4efbefdfc89bcbe63220f2bed4c70a5b65fec08921869d5cbc69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
